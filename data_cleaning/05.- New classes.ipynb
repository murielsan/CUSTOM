{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed2bbf6",
   "metadata": {},
   "source": [
    "## Load AudioSet data from file\n",
    "\n",
    "Data extracted by:\n",
    "https://github.com/qiuqiangkong/audioset_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e94b4f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.43 GiB for an array with shape (2041789, 10, 128) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m (X_train, y_train, train_video_id_list) \u001b[38;5;241m=\u001b[39m load_data(hdf5_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/bal_train.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m (X_eval, y_eval, eval_video_id_list) \u001b[38;5;241m=\u001b[39m load_data(hdf5_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/eval.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m (X_unbal, y_unbal, unbal_video_id_list) \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdf5_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/unbal_train.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Convert y from bool to int\u001b[39;00m\n\u001b[0;32m     24\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_train)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\t\t\t\u001b[38;5;66;03m# shape: (N, 527)\u001b[39;00m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(hdf5_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m hf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m video_id_list \u001b[38;5;241m=\u001b[39m hf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id_list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(y)\n\u001b[0;32m     15\u001b[0m video_id_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(video_id_list)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.43 GiB for an array with shape (2041789, 10, 128) and data type uint8"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "feat_dir = \"./features\"\n",
    "models_dir = \"./models\"\n",
    "hdf5_path = \"../dataset/packed_features\"\n",
    "\n",
    "def load_data(hdf5_path):\n",
    "    with h5py.File(hdf5_path, 'r') as hf:\n",
    "        x = hf.get('x')\n",
    "        y = hf.get('y')\n",
    "        video_id_list = hf.get('video_id_list')\n",
    "        x = np.array(x)\n",
    "        y = list(y)\n",
    "        video_id_list = list(video_id_list)\n",
    "        \n",
    "    return x, y, video_id_list\n",
    "\n",
    "(X_train, y_train, train_video_id_list) = load_data(hdf5_path+\"/bal_train.h5\")\n",
    "(X_eval, y_eval, eval_video_id_list) = load_data(hdf5_path+\"/eval.h5\")\n",
    "(X_unbal, y_unbal, unbal_video_id_list) = load_data(hdf5_path+\"/unbal_train.h5\")\n",
    "\n",
    "#Convert y from bool to int\n",
    "y_train = np.array(y_train).astype(int)\t\t\t# shape: (N, 527)\n",
    "y_eval = np.array(y_eval).astype(int)\n",
    "y_unbal = np.array(y_unbal).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15103bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classes_file = \"../dataset/class_labels_indices.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(classes_file)\n",
    "labels_df = labels_df.set_index('index')\n",
    "\n",
    "selected_classes = [\"Speech\", \"Musical instrument\", \"Car\", \"Dog\", \"Child speech, kid speaking\", \"Rail transport\",\n",
    "                    \"Siren\", \"Vehicle horn, car horn, honking\", \"Jackhammer\", \"Pigeon, dove\"]\n",
    "\n",
    "df_sel = labels_df[labels_df['display_name'].isin(selected_classes)]\n",
    "df_sel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab79219",
   "metadata": {},
   "source": [
    "## Filter training sets\n",
    "Select only our classes. Reduce from 527 to 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe56929",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_classes = list(df_sel.index)\n",
    "\n",
    "y_train_filtered = y_train[:,filter_classes]\n",
    "\n",
    "# Rows that contain only ONE of our classes\n",
    "filter_ = np.argwhere(np.sum(y_train_filtered, axis=1) == 1)\n",
    "y_train = y_train_filtered[filter_.flat]\n",
    "X_train = X_train[filter_.flat]\n",
    "train_video_id_list = np.array(train_video_id_list)[filter_.flat]\n",
    "\n",
    "y_eval_filtered = y_eval[:,filter_classes]\n",
    "\n",
    "filter_ = np.argwhere(np.sum(y_eval_filtered, axis=1) == 1)\n",
    "y_eval = y_eval_filtered[filter_.flat]\n",
    "X_eval = X_eval[filter_.flat]\n",
    "eval_video_id_list = np.array(eval_video_id_list)[filter_.flat]\n",
    "\n",
    "y_unbal_filtered = y_unbal[:,filter_classes]\n",
    "\n",
    "filter_ = np.argwhere(np.sum(y_unbal_filtered, axis=1) == 1)\n",
    "y_unbal = y_unbal_filtered[filter_.flat]\n",
    "X_unbal = X_unbal[filter_.flat]\n",
    "unbal_video_id_list = np.array(unbal_video_id_list)[filter_.flat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca06e8",
   "metadata": {},
   "source": [
    "## One hot encoding for our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c57ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([filter_classes])\n",
    "print(list(mlb.classes_))\n",
    "\n",
    "# Save mlb for our project\n",
    "dump_filename = f\"{feat_dir}/new_multiLabelBinarizer.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(mlb, dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e21a82",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01afaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Save training and evaluation sets\n",
    "Path(feat_dir).mkdir(exist_ok=True)   \n",
    "\n",
    "dump_filename = f\"{feat_dir}/new_X_train.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(X_train, dump_file)\n",
    "    \n",
    "dump_filename = f\"{feat_dir}/new_y_train.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(y_train, dump_file)\n",
    "    \n",
    "dump_filename = f\"{feat_dir}/new_X_eval.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(X_eval, dump_file)\n",
    "    \n",
    "dump_filename = f\"{feat_dir}/new_y_eval.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(y_eval, dump_file)\n",
    "    \n",
    "dump_filename = f\"{feat_dir}/new_X_unbal.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(X_unbal, dump_file)\n",
    "    \n",
    "dump_filename = f\"{feat_dir}/new_y_unbal.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(y_unbal, dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525be64",
   "metadata": {},
   "source": [
    "## Balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff12de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y_train)\n",
    "counters = {}\n",
    "for i in range(y_train.shape[1]):\n",
    "    counters[df_sel.iloc[i][\"display_name\"]] = y_df[i].value_counts().loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50bcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))    \n",
    "plt.bar(counters.keys(), counters.values(), 1)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f87f6",
   "metadata": {},
   "source": [
    "### Remove speech from the bar plot\n",
    "To make it more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d04467",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = dict(sorted(counters.items(), key=lambda item: item[1], reverse=True)[1:10])\n",
    "\n",
    "plt.figure(figsize=(20,4))    \n",
    "plt.bar(top.keys(), top.values(), 1)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c48aa",
   "metadata": {},
   "source": [
    "### Join balanced and unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((x_train, x_unbal))\n",
    "y = np.concatenate((y_train, y_unbal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y)\n",
    "counters = {}\n",
    "for i in range(y.shape[1]):\n",
    "    counters[df_sel.iloc[i][\"display_name\"]] = y_df[i].value_counts().loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75984bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))    \n",
    "plt.bar(counters.keys(), counters.values(), 1)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c0826",
   "metadata": {},
   "source": [
    "## Save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([selected_classes_indexes])\n",
    "print(list(mlb.classes_))\n",
    "\n",
    "# Save mlb for our project\n",
    "base_dir = \"./features/\"\n",
    "\n",
    "dump_filename = f\"{base_dir}multiLabelBinarizer.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(mlb, dump_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
