{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27e9a57",
   "metadata": {},
   "source": [
    "# Classification with classic Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1da33f",
   "metadata": {},
   "source": [
    "### Load training and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744db280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"./features/\"\n",
    "\n",
    "load_file = f\"{base_dir}X_train.pkl\"\n",
    "with open(load_file, \"rb\") as load_file:\n",
    "    X = pickle.load(load_file)\n",
    "    \n",
    "load_file = f\"{base_dir}y_train.pkl\"\n",
    "with open(load_file, \"rb\") as load_file:\n",
    "    y = pickle.load(load_file)\n",
    "    \n",
    "load_file = f\"{base_dir}X_val.pkl\"\n",
    "with open(load_file, \"rb\") as load_file:\n",
    "    X_val = pickle.load(load_file)\n",
    "    \n",
    "load_file = f\"{base_dir}y_val.pkl\"\n",
    "with open(load_file, \"rb\") as load_file:\n",
    "    y_val = pickle.load(load_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b9406",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b308c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file = f\"{base_dir}multiLabelBinarizer.pkl\"\n",
    "with open(load_file, \"rb\") as load_file:\n",
    "    mlb = pickle.load(load_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e32a81",
   "metadata": {},
   "source": [
    "### Test different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec19607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to one dimension for testing\n",
    "y_red = np.array([a.argmax() for a in y])\n",
    "y_val_red = np.array([y.argmax() for y in y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85a6e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************SGDClassifier************\n",
      "Acc: 0.5593457943925234, Bal_acc: 0.5236324731468529, Prec: 0.5898132929266139, Recall: 0.5593457943925234, F1: 0.5569301356174161\n",
      "-------------------------------------------\n",
      "Acc: 0.5359813084112149, Bal_acc: 0.507179791399078, Prec: 0.6438168709241187, Recall: 0.5359813084112149, F1: 0.5509031978550087\n",
      "-------------------------------------------\n",
      "Acc: 0.6044880785413744, Bal_acc: 0.5823679287726027, Prec: 0.6541573300548035, Recall: 0.6044880785413744, F1: 0.613818645174068\n",
      "-------------------------------------------\n",
      "Acc: 0.5642823749415615, Bal_acc: 0.5692967275454861, Prec: 0.6398387560072258, Recall: 0.5642823749415615, F1: 0.5849699907223391\n",
      "-------------------------------------------\n",
      "Acc: 0.5488546049555867, Bal_acc: 0.5293686706788285, Prec: 0.6369648244156135, Recall: 0.5488546049555867, F1: 0.5219629569145579\n",
      "-------------------------------------------\n",
      "************SGDCStandarized************\n",
      "Acc: 0.5738317757009346, Bal_acc: 0.5070831248056165, Prec: 0.5695382701782623, Recall: 0.5738317757009346, F1: 0.565243144449321\n",
      "-------------------------------------------\n",
      "Acc: 0.5967289719626169, Bal_acc: 0.5293707113376096, Prec: 0.5875962757907677, Recall: 0.5967289719626169, F1: 0.5864911665388282\n",
      "-------------------------------------------\n",
      "Acc: 0.6110331930808789, Bal_acc: 0.5618899623231289, Prec: 0.607572891595337, Recall: 0.6110331930808789, F1: 0.6061752071636298\n",
      "-------------------------------------------\n",
      "Acc: 0.5974754558204769, Bal_acc: 0.5478575058994625, Prec: 0.5918193575110104, Recall: 0.5974754558204769, F1: 0.5911636193066714\n",
      "-------------------------------------------\n",
      "Acc: 0.6049555867227676, Bal_acc: 0.5399439919099793, Prec: 0.6061400769952409, Recall: 0.6049555867227676, F1: 0.6010100451278166\n",
      "-------------------------------------------\n",
      "************LogisticRegression************\n",
      "Acc: 0.6032710280373832, Bal_acc: 0.5546584026267659, Prec: 0.6024598415350674, Recall: 0.6032710280373832, F1: 0.6005836570299008\n",
      "-------------------------------------------\n",
      "Acc: 0.6299065420560748, Bal_acc: 0.5733377504890547, Prec: 0.6209747992753356, Recall: 0.6299065420560748, F1: 0.6213626266972563\n",
      "-------------------------------------------\n",
      "Acc: 0.6432912575970079, Bal_acc: 0.5995746567391697, Prec: 0.6369764157432709, Recall: 0.6432912575970079, F1: 0.6367054484392964\n",
      "-------------------------------------------\n",
      "Acc: 0.6302010285179991, Bal_acc: 0.597546430859199, Prec: 0.6263411139229009, Recall: 0.6302010285179991, F1: 0.6255831078402423\n",
      "-------------------------------------------\n",
      "Acc: 0.6418887330528285, Bal_acc: 0.5799825702320074, Prec: 0.6312558344775108, Recall: 0.6418887330528285, F1: 0.6337715767378899\n",
      "-------------------------------------------\n",
      "************LrStandarized************\n",
      "Acc: 0.602803738317757, Bal_acc: 0.5531584259771961, Prec: 0.6015893877931644, Recall: 0.602803738317757, F1: 0.5998704783024276\n",
      "-------------------------------------------\n",
      "Acc: 0.6336448598130842, Bal_acc: 0.5765023064357737, Prec: 0.6238385525608846, Recall: 0.6336448598130842, F1: 0.6247174907292926\n",
      "-------------------------------------------\n",
      "Acc: 0.6432912575970079, Bal_acc: 0.5976229857384361, Prec: 0.6352284893876539, Recall: 0.6432912575970079, F1: 0.6363024920605885\n",
      "-------------------------------------------\n",
      "Acc: 0.6325385694249649, Bal_acc: 0.5994212700254392, Prec: 0.6294438903066729, Recall: 0.6325385694249649, F1: 0.6282461286609223\n",
      "-------------------------------------------\n",
      "Acc: 0.6395511921458625, Bal_acc: 0.5789280477415425, Prec: 0.6296728831387247, Recall: 0.6395511921458625, F1: 0.6316989231319402\n",
      "-------------------------------------------\n",
      "************RandomForestClassifier************\n",
      "Acc: 0.6257009345794392, Bal_acc: 0.555908678367085, Prec: 0.6239420388785482, Recall: 0.6257009345794392, F1: 0.6088626303177915\n",
      "-------------------------------------------\n",
      "Acc: 0.625233644859813, Bal_acc: 0.5437045860471061, Prec: 0.620056241903996, Recall: 0.625233644859813, F1: 0.6050077124927163\n",
      "-------------------------------------------\n",
      "Acc: 0.6442262739597943, Bal_acc: 0.5629430542526932, Prec: 0.6572230678381555, Recall: 0.6442262739597943, F1: 0.6235700360787839\n",
      "-------------------------------------------\n",
      "Acc: 0.6334735857877513, Bal_acc: 0.5608623336273384, Prec: 0.6377922840243875, Recall: 0.6334735857877513, F1: 0.6145908292325072\n",
      "-------------------------------------------\n",
      "Acc: 0.6442262739597943, Bal_acc: 0.5486365016256458, Prec: 0.6576126816726856, Recall: 0.6442262739597943, F1: 0.6213120389801562\n",
      "-------------------------------------------\n",
      "************ComplementNB************\n",
      "Acc: 0.5630841121495327, Bal_acc: 0.4868352698948423, Prec: 0.5309680053916341, Recall: 0.5630841121495327, F1: 0.5355202600594575\n",
      "-------------------------------------------\n",
      "Acc: 0.5616822429906542, Bal_acc: 0.4827474100941659, Prec: 0.5266976152244525, Recall: 0.5616822429906542, F1: 0.5281772947395645\n",
      "-------------------------------------------\n",
      "Acc: 0.595137914913511, Bal_acc: 0.5230121671621887, Prec: 0.5639386131723013, Recall: 0.595137914913511, F1: 0.563749581258406\n",
      "-------------------------------------------\n",
      "Acc: 0.552127162225339, Bal_acc: 0.4918494976960206, Prec: 0.527853620496488, Recall: 0.552127162225339, F1: 0.5221309679292644\n",
      "-------------------------------------------\n",
      "Acc: 0.5792426367461431, Bal_acc: 0.5009999310269787, Prec: 0.5942380687061144, Recall: 0.5792426367461431, F1: 0.5480042159001818\n",
      "-------------------------------------------\n",
      "************DecisionTreeClassifier************\n",
      "Acc: 0.44345794392523363, Bal_acc: 0.4031510448547876, Prec: 0.454301467359766, Recall: 0.44345794392523363, F1: 0.4478624110192125\n",
      "-------------------------------------------\n",
      "Acc: 0.4649532710280374, Bal_acc: 0.41542124832621347, Prec: 0.46415187754688075, Recall: 0.4649532710280374, F1: 0.46418034538274294\n",
      "-------------------------------------------\n",
      "Acc: 0.4946236559139785, Bal_acc: 0.44992075277022037, Prec: 0.49058434948424134, Recall: 0.4946236559139785, F1: 0.4919729656886798\n",
      "-------------------------------------------\n",
      "Acc: 0.4618980832164563, Bal_acc: 0.4180270672152406, Prec: 0.46815631976977307, Recall: 0.4618980832164563, F1: 0.4633760829447842\n",
      "-------------------------------------------\n",
      "Acc: 0.48200093501636276, Bal_acc: 0.41231883026153726, Prec: 0.4777283376982274, Recall: 0.48200093501636276, F1: 0.4790554782677975\n",
      "-------------------------------------------\n",
      "************HistGradientBoostingClassifier************\n",
      "Acc: 0.6336448598130842, Bal_acc: 0.5635379739519298, Prec: 0.6293628818196686, Recall: 0.6336448598130842, F1: 0.6251851942534747\n",
      "-------------------------------------------\n",
      "Acc: 0.6364485981308411, Bal_acc: 0.5567740113649198, Prec: 0.6323644111594688, Recall: 0.6364485981308411, F1: 0.6232166837317833\n",
      "-------------------------------------------\n",
      "Acc: 0.6573165030388032, Bal_acc: 0.5894876319940341, Prec: 0.6570826535633489, Recall: 0.6573165030388032, F1: 0.645478795128391\n",
      "-------------------------------------------\n",
      "Acc: 0.6470313230481534, Bal_acc: 0.5821161842621485, Prec: 0.6436592440701902, Recall: 0.6470313230481534, F1: 0.6341038229371089\n",
      "-------------------------------------------\n",
      "Acc: 0.6474988312295465, Bal_acc: 0.5651968069322951, Prec: 0.643248963449277, Recall: 0.6474988312295465, F1: 0.6336740194860069\n",
      "-------------------------------------------\n",
      "************SVC************\n",
      "Acc: 0.6434579439252337, Bal_acc: 0.5840165635166996, Prec: 0.6370181301510849, Recall: 0.6434579439252337, F1: 0.6358687113618144\n",
      "-------------------------------------------\n",
      "Acc: 0.6462616822429906, Bal_acc: 0.57163498318502, Prec: 0.6397058123723512, Recall: 0.6462616822429906, F1: 0.633309052552849\n",
      "-------------------------------------------\n",
      "Acc: 0.6746143057503506, Bal_acc: 0.6192605610973446, Prec: 0.6747097514571638, Recall: 0.6746143057503506, F1: 0.6662564027733353\n",
      "-------------------------------------------\n",
      "Acc: 0.6601215521271622, Bal_acc: 0.6144553354367319, Prec: 0.661317669317153, Recall: 0.6601215521271622, F1: 0.6523363149290571\n",
      "-------------------------------------------\n",
      "Acc: 0.6633941093969145, Bal_acc: 0.5888157061061299, Prec: 0.6569724039158354, Recall: 0.6633941093969145, F1: 0.6516512439563119\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import ComplementNB # Dice que es bueno para sets no balanceados\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier # Especiales multiclass\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Ya que los datos no est√°n bien balanceados, vamos a probar con un StratifiedKFold (aunque ya tengamos un 1.0)\n",
    "models = {'SGDClassifier': SGDClassifier(), 'SGDCStandarized': Pipeline([('standarize', StandardScaler()), \n",
    "            ('sgd', SGDClassifier())]),'LogisticRegression': LogisticRegression(max_iter=1000), 'LrStandarized': Pipeline([('standarize', StandardScaler()), \n",
    "            ('lr', LogisticRegression(max_iter=5000))]),'RandomForestClassifier': RandomForestClassifier(), 'ComplementNB': ComplementNB(), \n",
    "            'DecisionTreeClassifier': DecisionTreeClassifier(), 'HistGradientBoostingClassifier': HistGradientBoostingClassifier(),\n",
    "            'SVC': SVC()\n",
    "        }\n",
    "\n",
    "for model_tag, model in models.items():\n",
    "    print(f\"************{model_tag}************\")\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y_red):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y_red[train_index], y_red[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        bal_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        \n",
    "        print(f\"Acc: {accuracy}, Bal_acc: {bal_accuracy}, Prec: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "        print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25941bb1",
   "metadata": {},
   "source": [
    "### Try OneVSRest techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e29bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************RandomForestClassifier************\n",
      "Acc: 0.6322429906542056, Bal_acc: 0.5576368548699788, Prec: 0.6341390996701167, Recall: 0.6322429906542056, F1: 0.6184009081998519\n",
      "-------------------------------------------\n",
      "Acc: 0.6355140186915887, Bal_acc: 0.5574181231210386, Prec: 0.6364151808464261, Recall: 0.6355140186915887, F1: 0.6164339553925604\n",
      "-------------------------------------------\n",
      "Acc: 0.6470313230481534, Bal_acc: 0.5715425226278865, Prec: 0.6556866693933593, Recall: 0.6470313230481534, F1: 0.6290085397249165\n",
      "-------------------------------------------\n",
      "Acc: 0.6484338475923329, Bal_acc: 0.5821079058003412, Prec: 0.6538555804304789, Recall: 0.6484338475923329, F1: 0.6309784070300946\n",
      "-------------------------------------------\n",
      "Acc: 0.6470313230481534, Bal_acc: 0.5626207296844117, Prec: 0.6625688075292161, Recall: 0.6470313230481534, F1: 0.6291343720735867\n",
      "-------------------------------------------\n",
      "************HistGradientBoostingClassifier************\n",
      "Acc: 0.6224299065420561, Bal_acc: 0.5528489738307468, Prec: 0.6165532807229789, Recall: 0.6224299065420561, F1: 0.6128199772914551\n",
      "-------------------------------------------\n",
      "Acc: 0.6462616822429906, Bal_acc: 0.56628525900401, Prec: 0.6440631681926865, Recall: 0.6462616822429906, F1: 0.6315813198983837\n",
      "-------------------------------------------\n",
      "Acc: 0.6629266012155213, Bal_acc: 0.5952304595838472, Prec: 0.66371313225046, Recall: 0.6629266012155213, F1: 0.6501072637003503\n",
      "-------------------------------------------\n",
      "Acc: 0.6474988312295465, Bal_acc: 0.585231211346436, Prec: 0.645584886433182, Recall: 0.6474988312295465, F1: 0.6351608119217111\n",
      "-------------------------------------------\n",
      "Acc: 0.6423562412342216, Bal_acc: 0.5554206946796254, Prec: 0.6330630054756787, Recall: 0.6423562412342216, F1: 0.626354896927039\n",
      "-------------------------------------------\n",
      "************LinearSVC************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.4897196261682243, Bal_acc: 0.3508998220635418, Prec: 0.5956801982868698, Recall: 0.4897196261682243, F1: 0.43985892680140887\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.4995327102803738, Bal_acc: 0.4080614205211727, Prec: 0.6078611164359724, Recall: 0.4995327102803738, F1: 0.47205258055753274\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.4927536231884058, Bal_acc: 0.52321799670838, Prec: 0.6647185307034893, Recall: 0.4927536231884058, F1: 0.524359576469929\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.4941561477325853, Bal_acc: 0.4037935078516054, Prec: 0.6112593992207624, Recall: 0.4941561477325853, F1: 0.4650391778206846\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.6002805049088359, Bal_acc: 0.519164434263372, Prec: 0.6202787500055076, Recall: 0.6002805049088359, F1: 0.5909176602421848\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm250119\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models = {'RandomForestClassifier': RandomForestClassifier(), 'HistGradientBoostingClassifier': HistGradientBoostingClassifier(),\n",
    "          'LinearSVC': LinearSVC(max_iter=10000)\n",
    "        }\n",
    "\n",
    "for model_tag, model in models.items():\n",
    "    print(f\"************{model_tag}************\")\n",
    "    skf = StratifiedKFold(n_splits=5)    \n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y_red):\n",
    "        X_train, X_test = X[train_index], X[test_index]        \n",
    "        y_train, y_test = y_red[train_index], y_red[test_index]\n",
    "        \n",
    "        ovrc = OneVsRestClassifier(model).fit(X_train, y_train)        \n",
    "        y_pred = ovrc.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        bal_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        \n",
    "        print(f\"Acc: {accuracy}, Bal_acc: {bal_accuracy}, Prec: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "        print(\"-------------------------------------------\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe770ab",
   "metadata": {},
   "source": [
    "### Test different hyperparams for RandomForest\n",
    "RandomForestClassifier seems to be the best, let's try different hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a815754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m model_tunning \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator \u001b[38;5;241m=\u001b[39m ovr, param_distributions \u001b[38;5;241m=\u001b[39m random_grid, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m#n_jobs = -1 se come la cpu\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Fit the random search model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel_tunning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_tunning\u001b[38;5;241m.\u001b[39mbest_score_)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_tunning\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1765\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1766\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'estimator__n_estimators': n_estimators,\n",
    "               'estimator__max_features': max_features,\n",
    "               'estimator__max_depth': max_depth,\n",
    "               'estimator__min_samples_split': min_samples_split,\n",
    "               'estimator__min_samples_leaf': min_samples_leaf,\n",
    "               'estimator__bootstrap': bootstrap}\n",
    "\n",
    "ovr = OneVsRestClassifier(RandomForestClassifier())\n",
    "model_tunning = RandomizedSearchCV(estimator = ovr, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, n_jobs = 2) #n_jobs = -1 se come la cpu\n",
    "# Fit the random search model\n",
    "model_tunning.fit(X, y)\n",
    "\n",
    "print(model_tunning.best_score_)\n",
    "print(model_tunning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71b8580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.6350467289719626, Bal_acc: 0.5568489420464032, Prec: 0.6302391324628442, Recall: 0.6350467289719626, F1: 0.617750679689817\n",
      "Acc: 0.6308411214953271, Bal_acc: 0.5499028275187472, Prec: 0.6332506733594748, Recall: 0.6308411214953271, F1: 0.6117795514513703\n",
      "Acc: 0.648901355773726, Bal_acc: 0.5702959488139603, Prec: 0.6597347686370506, Recall: 0.648901355773726, F1: 0.6315333705600262\n",
      "Acc: 0.6465638148667602, Bal_acc: 0.579677042823108, Prec: 0.6569017797598655, Recall: 0.6465638148667602, F1: 0.6284655048281669\n",
      "Acc: 0.6432912575970079, Bal_acc: 0.5550280071217134, Prec: 0.6553652955796706, Recall: 0.6432912575970079, F1: 0.6238180899118312\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, min_samples_split=5, min_samples_leaf=1, \n",
    "                               max_features='sqrt', max_depth=None, bootstrap=False)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)    \n",
    "    \n",
    "for train_index, test_index in skf.split(X, y_red):\n",
    "    X_train, X_test = X[train_index], X[test_index]        \n",
    "    y_train, y_test = y_red[train_index], y_red[test_index]\n",
    "      \n",
    "    #ovrc = OneVsRestClassifier(model).fit(X_train, y_train)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    bal_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        \n",
    "    print(f\"Acc: {accuracy}, Bal_acc: {bal_accuracy}, Prec: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f380d02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "0.6283313337738358\n",
      "{'n_estimators': 739, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 20)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "## RUNNING THIS TAKES A LOT OF TIME\n",
    "# model_tunning = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, scoring='f1_weighted', \n",
    "                                   n_iter = 50, cv = 5, verbose=2, n_jobs = 4) #n_jobs = -1 se come la cpu\n",
    "# Fit the random search model\n",
    "model_tunning.fit(X, y_red)\n",
    "\n",
    "print(model_tunning.best_score_)\n",
    "print(model_tunning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a19456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(model_tunning.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e6fffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=0a7f2f42-bd31-4952-9333-36eea8b12294 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('0a7f2f42-bd31-4952-9333-36eea8b12294').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>169.823963</td>\n",
       "      <td>3.465020</td>\n",
       "      <td>1.365002</td>\n",
       "      <td>0.184131</td>\n",
       "      <td>739</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 739, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}</td>\n",
       "      <td>0.625889</td>\n",
       "      <td>0.613578</td>\n",
       "      <td>0.639824</td>\n",
       "      <td>0.634983</td>\n",
       "      <td>0.627382</td>\n",
       "      <td>0.628331</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>85.309796</td>\n",
       "      <td>4.169874</td>\n",
       "      <td>0.538199</td>\n",
       "      <td>0.155772</td>\n",
       "      <td>374</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 374, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}</td>\n",
       "      <td>0.623442</td>\n",
       "      <td>0.612791</td>\n",
       "      <td>0.632557</td>\n",
       "      <td>0.630678</td>\n",
       "      <td>0.624244</td>\n",
       "      <td>0.624742</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>185.918416</td>\n",
       "      <td>4.231527</td>\n",
       "      <td>1.416732</td>\n",
       "      <td>0.155078</td>\n",
       "      <td>843</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 843, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': False}</td>\n",
       "      <td>0.625812</td>\n",
       "      <td>0.607099</td>\n",
       "      <td>0.635640</td>\n",
       "      <td>0.631490</td>\n",
       "      <td>0.622360</td>\n",
       "      <td>0.624480</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>216.571228</td>\n",
       "      <td>5.534254</td>\n",
       "      <td>1.492288</td>\n",
       "      <td>0.155890</td>\n",
       "      <td>947</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 947, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False}</td>\n",
       "      <td>0.626371</td>\n",
       "      <td>0.607433</td>\n",
       "      <td>0.633672</td>\n",
       "      <td>0.626755</td>\n",
       "      <td>0.626405</td>\n",
       "      <td>0.624127</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.848386</td>\n",
       "      <td>0.913423</td>\n",
       "      <td>0.273792</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 218, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 70, 'bootstrap': False}</td>\n",
       "      <td>0.624720</td>\n",
       "      <td>0.609610</td>\n",
       "      <td>0.635107</td>\n",
       "      <td>0.626176</td>\n",
       "      <td>0.624569</td>\n",
       "      <td>0.624036</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "17     169.823963      3.465020         1.365002        0.184131   \n",
       "31      85.309796      4.169874         0.538199        0.155772   \n",
       "13     185.918416      4.231527         1.416732        0.155078   \n",
       "21     216.571228      5.534254         1.492288        0.155890   \n",
       "28      30.848386      0.913423         0.273792        0.021918   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "17                739                       5                      1   \n",
       "31                374                       5                      2   \n",
       "13                843                       2                      2   \n",
       "21                947                      10                      1   \n",
       "28                218                       2                      2   \n",
       "\n",
       "   param_max_features param_max_depth param_bootstrap  \\\n",
       "17               sqrt             100           False   \n",
       "31               sqrt            None           False   \n",
       "13               sqrt              50           False   \n",
       "21               sqrt              40           False   \n",
       "28               log2              70           False   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "17  {'n_estimators': 739, 'min_samples_split': 5, ...           0.625889   \n",
       "31  {'n_estimators': 374, 'min_samples_split': 5, ...           0.623442   \n",
       "13  {'n_estimators': 843, 'min_samples_split': 2, ...           0.625812   \n",
       "21  {'n_estimators': 947, 'min_samples_split': 10,...           0.626371   \n",
       "28  {'n_estimators': 218, 'min_samples_split': 2, ...           0.624720   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "17           0.613578           0.639824           0.634983   \n",
       "31           0.612791           0.632557           0.630678   \n",
       "13           0.607099           0.635640           0.631490   \n",
       "21           0.607433           0.633672           0.626755   \n",
       "28           0.609610           0.635107           0.626176   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "17           0.627382         0.628331        0.008954                1  \n",
       "31           0.624244         0.624742        0.006943                2  \n",
       "13           0.622360         0.624480        0.009819                3  \n",
       "21           0.626405         0.624127        0.008797                4  \n",
       "28           0.624569         0.624036        0.008198                5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['rank_test_score'],axis=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ee1913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.6119847399274216, Bal_acc: 0.5257601053229649, Prec: 0.6444412191273847, Recall: 0.6119847399274216, F1: 0.5934413707722972\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=739, min_samples_split=5, min_samples_leaf=1, \n",
    "                               max_features='sqrt', max_depth=100, bootstrap=False)\n",
    "\n",
    "model.fit(X,y_red)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val_red, y_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_val_red, y_pred)\n",
    "precision = precision_score(y_val_red, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_val_red, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_val_red, y_pred, average=\"weighted\")\n",
    "        \n",
    "print(f\"Acc: {accuracy}, Bal_acc: {bal_accuracy}, Prec: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0211f9a",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97733618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model for our project (Accuracy 0.612)\n",
    "base_dir = \"./models/\"\n",
    "\n",
    "dump_filename = f\"{base_dir}random_forest_classifier.pkl\"\n",
    "with open(dump_filename, \"wb\") as dump_file:\n",
    "    pickle.dump(mlb, dump_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
